# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved
"""
PIDæ•°æ®é›†å¤„ç† - åŸºäºåŸå§‹ç‰ˆæœ¬æ¢å¤ï¼Œæ”¯æŒGraphMLæ ¼å¼æ ‡æ³¨å’ŒCOCOå…¼å®¹æ€§
"""
import os
import sys
import torch
import torchvision
import torchvision.transforms as T
import torchvision.datasets as datasets
import numpy as np
from torch.utils.data import Dataset, DataLoader, Subset
from PIL import Image, ImageFile
import networkx as nx
import random
import tempfile
import json
from pycocotools.coco import COCO

# å…è®¸åŠ è½½è¢«æˆªæ–­çš„å›¾åƒ
ImageFile.LOAD_TRUNCATED_IMAGES = True


class PIDGraphDatasetExtractor:
    """PIDæ•°æ®é›†æå–å™¨ï¼Œå¤„ç†GraphMLæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶"""
    
    def __init__(self, base_dir):
        self.base_dir = base_dir
        self.data_info = []
        

    def extract(self):
        """æå–æ‰€æœ‰é…å¯¹çš„å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶"""
        paired_files = []
        for root, dirs, files in os.walk(self.base_dir):
            # æŒ‰æ–‡ä»¶ååˆ†ç»„
            file_groups = {}
            
            for file in files:
                base_name = os.path.splitext(file)[0]
                ext = os.path.splitext(file)[1].lower()
                
                if base_name not in file_groups:
                    file_groups[base_name] = {}
                
                if ext in ['.png', '.jpg', '.jpeg']:
                    file_groups[base_name]['image'] = os.path.join(root, file)
                elif ext == '.graphml':
                    file_groups[base_name]['annotation'] = os.path.join(root, file)
            
            # æ‰¾åˆ°å®Œæ•´é…å¯¹çš„æ–‡ä»¶
            for base_name, files_dict in file_groups.items():
                if 'image' in files_dict and 'annotation' in files_dict:
                    paired_files.append({
                        'id': base_name,
                        'image_path': files_dict['image'],
                        'annotation_path': files_dict['annotation'],
                        'relative_path': os.path.relpath(root, self.base_dir)
                    })

        print(f"åœ¨ {self.base_dir} ä¸­æ‰¾åˆ° {len(paired_files)} å¯¹é…å¯¹æ–‡ä»¶")
        return paired_files
    
    def extract_annotations_from_graphml(self, graphml_path):
        """ä» GraphML æ–‡ä»¶ä¸­æå–æ ‡æ³¨ä¿¡æ¯"""
        try:
            graph = nx.read_graphml(graphml_path)
            
            # æå–èŠ‚ç‚¹ï¼ˆå¯¹è±¡ï¼‰ä¿¡æ¯
            objects = []
            for node_id, node_attrs in graph.nodes(data=True):
                # æ£€æŸ¥æ˜¯å¦æœ‰è¾¹ç•Œæ¡†ä¿¡æ¯
                bbox_keys = ['xmin', 'ymin', 'xmax', 'ymax']
                if all(key in node_attrs for key in bbox_keys):
                    try:
                        bbox = [float(node_attrs[key]) for key in bbox_keys]
                        
                        obj_info = {
                            'id': node_id,
                            'bbox': bbox,  # [xmin, ymin, xmax, ymax]
                            'label': node_attrs.get('label', 'unknown'),
                            'category': node_attrs.get('category', 'object'),
                            'attributes': {k: v for k, v in node_attrs.items() 
                                         if k not in bbox_keys + ['label', 'category']}
                        }
                        objects.append(obj_info)
                    except (ValueError, TypeError):
                        continue
            
            # æå–è¾¹ï¼ˆå…³ç³»ï¼‰ä¿¡æ¯
            relations = []
            for src, dst, edge_attrs in graph.edges(data=True):
                rel_info = {
                    'subject': src,
                    'object': dst,
                    'predicate': edge_attrs.get('edge_label', 'unknown'),
                    'attributes': dict(edge_attrs)
                }
                relations.append(rel_info)
            
            return {
                'objects': objects,
                'relations': relations,
                'num_objects': len(objects),
                'num_relations': len(relations)
            }
            
        except Exception as e:
            print(f"è§£æ GraphML æ–‡ä»¶å¤±è´¥ {graphml_path}: {e}")
            return None


class PIDGraphDataset(Dataset):
    """PIDå›¾æ•°æ®é›†ç±»ï¼Œæ”¯æŒGraphMLæ ¼å¼çš„æ ‡æ³¨"""
    
    def __init__(self, complete_img=False, min_objects=1, transform=None, base_path='data/PID'):
        if complete_img == False:
            self.base_dir = os.path.join(base_path, 'patched')
        else:
            self.base_dir = os.path.join(base_path, 'Complete')
            
        self.transform = transform
        
        # 1. åŠ è½½å…³ç³»ç±»åˆ«é…ç½®
        self.rel_categories = ['__background__',      # 0 - èƒŒæ™¯ç±»åˆ«
                               'solid',            # 1 - å®çº¿è¿æ¥
                               'non-solid',       # 2 - è™šçº¿è¿æ¥
                               ]
        
        # 2. åˆ›å»ºå…³ç³»ç±»åˆ«æ˜ å°„
        self.relation_label_to_idx = {rel: idx for idx, rel in enumerate(self.rel_categories)}
        self.idx_to_relation_label = {idx: rel for idx, rel in enumerate(self.rel_categories)}
        
        # 3. åŠ è½½å¯¹è±¡ç±»åˆ«
        self.obj_categories = [
            '__background__',     # 0 - èƒŒæ™¯
            'pump',              # 1 - æ³µ
            'valve',             # 2 - é˜€é—¨
            'tank',              # 3 - å‚¨ç½
            'pipe',              # 4 - ç®¡é“
            'sensor',            # 5 - ä¼ æ„Ÿå™¨
            'motor',             # 6 - ç”µæœº
            'heat_exchanger',    # 7 - æ¢çƒ­å™¨
            'compressor',        # 8 - å‹ç¼©æœº
            'filter',            # 9 - è¿‡æ»¤å™¨
            'control_valve',     # 10 - è°ƒèŠ‚é˜€
            'pressure_vessel',   # 11 - å‹åŠ›å®¹å™¨
            'instrument',        # 12 - ä»ªè¡¨
        ]
        
        self.label_to_idx = {
            obj: idx for idx, obj in enumerate(self.obj_categories)
        }
        
        self.idx_to_label = {
            idx: obj for idx, obj in enumerate(self.obj_categories)
        }
        
        # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.base_dir):
            print(f"âš ï¸ è­¦å‘Š: PIDæ•°æ®ç›®å½•ä¸å­˜åœ¨ {self.base_dir}")
            print(f"   è¯·ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®ï¼Œæˆ–æ•°æ®å·²æ­£ç¡®æ”¾ç½®")
            self.valid_samples = []
            self._create_minimal_mappings()
            return
            
        # æå–æ•°æ®é›†ä¿¡æ¯
        self.extractor = PIDGraphDatasetExtractor(self.base_dir)
        self.paired_files = self.extractor.extract()
        
        # éªŒè¯å¹¶è¿‡æ»¤æœ‰æ•ˆæ ·æœ¬
        self.valid_samples = []
        print("éªŒè¯æ ·æœ¬...")
        
        for i, pair in enumerate(self.paired_files):
            annotations = self.extractor.extract_annotations_from_graphml(pair['annotation_path'])
            
            if annotations and annotations['num_objects'] >= min_objects:
                pair['annotations'] = annotations
                self.valid_samples.append(pair)
        
        print(f"\næ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"  åŸå§‹é…å¯¹: {len(self.paired_files)}")
        print(f"  æœ‰æ•ˆæ ·æœ¬: {len(self.valid_samples)}")
        
        if len(self.valid_samples) > 0:
            self._create_label_mappings()
        else:
            self._create_minimal_mappings()

    def _create_minimal_mappings(self):
        """åˆ›å»ºæœ€å°æ ‡ç­¾æ˜ å°„ï¼ˆå½“æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬æ—¶ï¼‰"""
        self.object_classes = self.obj_categories
        self.relation_classes = self.rel_categories
        self.object_label_to_idx = self.label_to_idx
        self.idx_to_object_label = self.idx_to_label
        self.num_object_classes = len(self.object_classes)
        self.num_relation_classes = len(self.relation_classes)
        print(f"  ä½¿ç”¨é»˜è®¤ç±»åˆ«æ˜ å°„")

    def _create_label_mappings(self):
        """åˆ›å»ºæ ‡ç­¾æ˜ å°„"""
        all_object_labels = set()
        all_relation_labels = set()
        
        for sample in self.valid_samples:
            for obj in sample['annotations']['objects']:
                all_object_labels.add(obj['label'])
            for rel in sample['annotations']['relations']:
                all_relation_labels.add(rel['predicate'])
        
        # å¯¹è±¡æ ‡ç­¾æ˜ å°„ï¼ˆæ·»åŠ èƒŒæ™¯ç±»ï¼‰
        self.object_classes = ['__background__'] + sorted(list(all_object_labels))
        self.object_label_to_idx = {label: idx for idx, label in enumerate(self.object_classes)}
        self.idx_to_object_label = {idx: label for label, idx in self.object_label_to_idx.items()}
        self.num_object_classes = len(self.object_classes)
        
        # å…³ç³»æ ‡ç­¾æ˜ å°„ï¼ˆæ·»åŠ èƒŒæ™¯ç±»ï¼‰
        self.relation_classes = ['__background__'] + sorted(list(all_relation_labels))
        self.relation_label_to_idx = {label: idx for idx, label in enumerate(self.relation_classes)}
        self.idx_to_relation_label = {idx: label for label, idx in self.relation_label_to_idx.items()}
        self.num_relation_classes = len(self.relation_classes)
        
        print(f"  å¯¹è±¡ç±»åˆ«: {self.num_object_classes} ä¸ª")
        print(f"  å…³ç³»ç±»åˆ«: {self.num_relation_classes} ä¸ª")
    
    def __len__(self):
        return len(self.valid_samples)
    
    def __getitem__(self, idx):
        """è¿”å›å›¾åƒã€ç›®æ ‡æ ‡æ³¨å’Œæ ·æœ¬ä¿¡æ¯"""
        if len(self.valid_samples) == 0:
            # è¿”å›ç©ºæ ·æœ¬
            dummy_image = Image.new('RGB', (800, 600), color=(128, 128, 128))
            if self.transform:
                dummy_image = self.transform(dummy_image)
            
            target = {
                'boxes': torch.zeros((0, 4), dtype=torch.float32),
                'labels': torch.zeros((0,), dtype=torch.int64),
                'image_id': torch.tensor([idx + 1], dtype=torch.int64),
                'orig_size': torch.tensor([600, 800]),
                'rel_annotations': torch.zeros((0, 3), dtype=torch.int64),
                'size': torch.tensor([600, 800]),
                'iscrowd': torch.zeros((0,), dtype=torch.int64)
            }
            return dummy_image, target
            
        sample = self.valid_samples[idx]
        
        # 1. å®‰å…¨åŠ è½½å›¾åƒ
        try:
            image = Image.open(sample['image_path']).convert('RGB')
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•åŠ è½½å›¾åƒ {sample['image_path']}: {e}")
            image = Image.new('RGB', (800, 600), color=(128, 128, 128))
            
        orig_size = torch.tensor([image.size[1], image.size[0]])  # (height, width)
        
        # 2. å¤„ç†æ ‡æ³¨
        annotations = sample['annotations']
        
        # æå–å¯¹è±¡ä¿¡æ¯
        boxes = []
        labels = []
        object_ids = []
        
        for obj in annotations['objects']:
            boxes.append(obj['bbox'])  # [xmin, ymin, xmax, ymax]
            # è·å–æ ‡ç­¾ç´¢å¼•ï¼ˆè·³è¿‡èƒŒæ™¯ç±»ï¼Œä»1å¼€å§‹ï¼‰
            label_idx = self.object_label_to_idx.get(obj['label'], 1)  # é»˜è®¤ä¸ºç¬¬ä¸€ä¸ªçœŸå®ç±»åˆ«
            labels.append(label_idx)
            object_ids.append(obj['id'])
        
        # æå–å…³ç³»ä¿¡æ¯
        rel_annotations = []
        for rel in annotations['relations']:
            try:
                # æ‰¾åˆ°ä¸»ä½“å’Œå®¢ä½“åœ¨å¯¹è±¡åˆ—è¡¨ä¸­çš„ç´¢å¼•
                sub_idx = object_ids.index(rel['subject'])
                obj_idx = object_ids.index(rel['object'])
                rel_label = self.relation_label_to_idx.get(rel['predicate'], 1)
                rel_annotations.append([sub_idx, obj_idx, rel_label])
            except ValueError:
                # è·³è¿‡æ‰¾ä¸åˆ°å¯¹åº”å¯¹è±¡çš„å…³ç³»
                continue
        
        # 3. è½¬æ¢ä¸ºå¼ é‡
        if len(boxes) > 0:
            boxes = torch.as_tensor(boxes, dtype=torch.float32)
            labels = torch.as_tensor(labels, dtype=torch.int64)
        else:
            # å¤„ç†æ²¡æœ‰å¯¹è±¡çš„æƒ…å†µ
            boxes = torch.zeros((0, 4), dtype=torch.float32)
            labels = torch.zeros((0,), dtype=torch.int64)
        
        if len(rel_annotations) > 0:
            rel_annotations = torch.as_tensor(rel_annotations, dtype=torch.int64)
        else:
            rel_annotations = torch.zeros((0, 3), dtype=torch.int64)
        
        # 4. æ„å»ºç›®æ ‡å­—å…¸
        target = {
            'boxes': boxes,                    # [N, 4] è¾¹ç•Œæ¡†
            'labels': labels,                  # [N] å¯¹è±¡æ ‡ç­¾
            'image_id': torch.tensor([idx + 1], dtype=torch.int64),   # [1] å›¾åƒID
            'orig_size': orig_size,            # [2] åŸå§‹å›¾åƒå°ºå¯¸ [H, W]
            'rel_annotations': rel_annotations,  # [M, 3] - [subject_idx, object_idx, relation_label]
            'size': orig_size,              # [2] å›¾åƒå°ºå¯¸ [H, W]
            'iscrowd': torch.zeros(len(boxes), dtype=torch.int64)
        }
        
        # 5. åº”ç”¨å›¾åƒå˜æ¢
        if self.transform:
            image = self.transform(image)
        
        return image, target
    
    def get_dataset_info(self):
        """è·å–æ•°æ®é›†ä¿¡æ¯"""
        return {
            'total_samples': len(self.valid_samples),
            'object_classes': self.object_classes,
            'relation_classes': self.relation_classes,
            'num_object_classes': self.num_object_classes,
            'num_relation_classes': self.num_relation_classes
        }


class CocoCompatibleDataset(torchvision.datasets.CocoDetection):
    """COCO å…¼å®¹çš„æ•°æ®é›†åŒ…è£…ç±»"""
    
    def __init__(self, original_dataset, indices=None):
        # ä¸è°ƒç”¨çˆ¶ç±»çš„ __init__ï¼Œå› ä¸ºæˆ‘ä»¬è¦è‡ªå®šä¹‰è¡Œä¸º
        self.original_dataset = original_dataset
        self.indices = indices if indices is not None else list(range(len(original_dataset)))
        
        # ğŸ”‘ åˆ›å»º COCO API å¯¹è±¡
        self.coco = self._create_coco_api()
        
        # å¤åˆ¶åŸæ•°æ®é›†çš„å±æ€§
        self.rel_categories = getattr(original_dataset, 'rel_categories', ['__background__'])
        self.obj_categories = getattr(original_dataset, 'obj_categories', ['__background__'])
        
    def __len__(self):
        return len(self.indices)
    
    def __getitem__(self, idx):
        # è·å–çœŸå®çš„ç´¢å¼•
        real_idx = self.indices[idx]
        return self.original_dataset[real_idx]
    
    def _create_coco_api(self):
        """åˆ›å»º COCO API å¯¹è±¡"""
        try:
            # æ„å»º COCO æ ¼å¼æ•°æ®
            images = []
            annotations = []
            categories = []
            
            # è·å–ç±»åˆ«ä¿¡æ¯
            obj_categories = getattr(self.original_dataset, 'obj_categories', ['__background__', 'object'])
            
            # åˆ›å»ºç±»åˆ«ï¼ˆè·³è¿‡èƒŒæ™¯ç±»ï¼‰
            for i, cat_name in enumerate(obj_categories):
                if i == 0:  # è·³è¿‡èƒŒæ™¯ç±»
                    continue
                categories.append({
                    "id": i,
                    "name": cat_name,
                    "supercategory": "thing"
                })
            
            if not categories:
                categories.append({"id": 1, "name": "object", "supercategory": "thing"})
            
            # å¤„ç†æ ·æœ¬ï¼ˆé™åˆ¶æ•°é‡é¿å…å†…å­˜é—®é¢˜ï¼‰
            num_samples = min(len(self.indices), 50)
            ann_id = 1
            
            for i in range(num_samples):
                try:
                    real_idx = self.indices[i]
                    image, target = self.original_dataset[real_idx]
                    
                    # å›¾åƒä¿¡æ¯
                    if 'orig_size' in target:
                        h, w = target['orig_size'].tolist()
                    else:
                        h, w = 800, 800
                    
                    image_info = {
                        "id": i + 1,
                        "width": w,
                        "height": h,
                        "file_name": f"image_{real_idx}.jpg"
                    }
                    images.append(image_info)
                    
                    # æ ‡æ³¨ä¿¡æ¯
                    if 'boxes' in target and 'labels' in target:
                        boxes = target['boxes']
                        labels = target['labels']
                        
                        for box, label in zip(boxes, labels):
                            if len(box) == 4 and label.item() > 0:
                                x1, y1, x2, y2 = box.tolist()
                                annotation = {
                                    "id": ann_id,
                                    "image_id": i + 1,
                                    "category_id": int(label.item()),
                                    "bbox": [x1, y1, x2 - x1, y2 - y1],
                                    "area": (x2 - x1) * (y2 - y1),
                                    "iscrowd": 0
                                }
                                annotations.append(annotation)
                                ann_id += 1
                except Exception as e:
                    print(f"å¤„ç†æ ·æœ¬ {i} æ—¶å‡ºé”™: {e}")
                    continue
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªå›¾åƒå’Œæ ‡æ³¨
            if not images:
                images.append({"id": 1, "width": 800, "height": 800, "file_name": "dummy.jpg"})
            
            if not annotations:
                annotations.append({
                    "id": 1, "image_id": 1, "category_id": 1,
                    "bbox": [100, 100, 100, 100], "area": 10000, "iscrowd": 0
                })
            
            # åˆ›å»º COCO æ•°æ®
            coco_data = {
                "images": images,
                "annotations": annotations,
                "categories": categories,
                "info": {"description": "PID Dataset in COCO format", "version": "1.0"}
            }
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False)
            json.dump(coco_data, temp_file, indent=2)
            temp_file.close()
            
            try:
                coco_api = COCO(temp_file.name)
                os.unlink(temp_file.name)
                print(f"âœ… åˆ›å»º COCO API: {len(images)} å›¾åƒ, {len(annotations)} æ ‡æ³¨")
                return coco_api
            except Exception as e:
                print(f"âŒ COCO API åˆ›å»ºå¤±è´¥: {e}")
                if os.path.exists(temp_file.name):
                    os.unlink(temp_file.name)
                return self._create_minimal_coco_api()
                
        except Exception as e:
            print(f"âŒ _create_coco_api å‡ºé”™: {e}")
            return self._create_minimal_coco_api()
    
    def _create_minimal_coco_api(self):
        """åˆ›å»ºæœ€å°çš„ COCO API"""
        dummy_data = {
            "images": [{"id": 1, "width": 800, "height": 800, "file_name": "dummy.jpg"}],
            "annotations": [{"id": 1, "image_id": 1, "category_id": 1, "bbox": [100, 100, 100, 100], "area": 10000, "iscrowd": 0}],
            "categories": [{"id": 1, "name": "object", "supercategory": "thing"}]
        }
        
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False)
        json.dump(dummy_data, temp_file)
        temp_file.close()
        
        try:
            coco_api = COCO(temp_file.name)
            os.unlink(temp_file.name)
            return coco_api
        except:
            if os.path.exists(temp_file.name):
                os.unlink(temp_file.name)
            return None


def create_transforms(train=True):
    """åˆ›å»ºæ•°æ®å˜æ¢"""
    if train:
        return T.Compose([
            T.Resize((800, 800)),
            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    else:
        return T.Compose([
            T.Resize((800, 800)),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])


def build_pid_dataset(image_set, args):
    """æ„å»ºPIDæ•°æ®é›†"""
    # è·å–æ•°æ®è·¯å¾„
    if hasattr(args, 'pid_path'):
        base_path = args.pid_path
    else:
        base_path = 'data/PID'
    
    # åˆ›å»ºå˜æ¢
    transform = create_transforms(train=(image_set == 'train'))
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†
    dataset = PIDGraphDataset(
        complete_img=False,  # é»˜è®¤ä½¿ç”¨patchedæ•°æ®
        min_objects=1,
        transform=transform,
        base_path=base_path
    )
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆæ ·æœ¬ï¼Œç›´æ¥è¿”å›åŸæ•°æ®é›†
    if len(dataset) == 0:
        print(f"âš ï¸ è­¦å‘Š: {image_set} æ•°æ®é›†ä¸ºç©º")
        return dataset
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    total_size = len(dataset)
    if image_set == 'train':
        # ä½¿ç”¨å‰80%ä½œä¸ºè®­ç»ƒé›†
        train_size = int(total_size * 0.8)
        indices = list(range(train_size))
    else:
        # ä½¿ç”¨å20%ä½œä¸ºéªŒè¯é›†
        train_size = int(total_size * 0.8)
        indices = list(range(train_size, total_size))
    
    # åˆ›å»ºCOCOå…¼å®¹æ•°æ®é›†
    coco_dataset = CocoCompatibleDataset(dataset, indices)
    
    print(f"âœ… æ„å»º {image_set} æ•°æ®é›†: {len(coco_dataset)} æ ·æœ¬")
    
    return coco_dataset
    """æ„å»ºPIDæ•°æ®é›†"""
    
    # åˆ›å»ºæ•°æ®å˜æ¢
    transforms = create_transforms(image_set == 'train')
    
    # æ•°æ®é›†è·¯å¾„
    img_folder = args.pid_path / f"{image_set}"
    ann_file = args.pid_path / "annotations" / f"instances_{image_set}.json"
    
    dataset = PIDDataset(
        img_folder=img_folder,
        ann_file=ann_file,
        transforms=transforms,
        return_masks=False
    )
    
    print(f"ğŸ“Š {image_set} æ•°æ®é›†: {len(dataset)} å¼ å›¾åƒ")
    
    return dataset


def create_transforms(train=True):
    """åˆ›å»ºæ•°æ®å˜æ¢"""
    
    normalize = T.Compose([
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    if train:
        return T.Compose([
            T.RandomHorizontalFlip(),
            T.RandomResize([480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800], max_size=1333),
            normalize,
        ])
    else:
        return T.Compose([
            T.RandomResize([800], max_size=1333),
            normalize,
        ])


class PIDDataset(CocoDetection):
    """PIDæ•°æ®é›†ç±» - ç»§æ‰¿è‡ªæ ‡å‡†CocoDetectionï¼Œå¢åŠ é”™è¯¯å¤„ç†"""
    
    def __init__(self, img_folder, ann_file, transforms=None, return_masks=False):
        self.img_folder = img_folder
        self.ann_file = ann_file
        self._transforms = transforms
        self.return_masks = return_masks
        
        # åŠ è½½COCOæ ¼å¼çš„æ³¨é‡Š
        with open(ann_file, 'r') as f:
            self.coco_data = json.load(f)
        
        # åˆ›å»ºå›¾åƒIDåˆ°æ–‡ä»¶åçš„æ˜ å°„
        self.id_to_filename = {img['id']: img['file_name'] for img in self.coco_data['images']}
        self.ids = list(self.id_to_filename.keys())
        
        print(f"âœ… åŠ è½½PIDæ•°æ®é›†: {len(self.ids)} å¼ å›¾åƒ")
    
    def __getitem__(self, idx):
        """è·å–æ•°æ®é¡¹"""
        img_id = self.ids[idx]
        filename = self.id_to_filename[img_id]
        img_path = os.path.join(self.img_folder, filename)
        
        # å®‰å…¨åŠ è½½å›¾åƒ
        img = safe_load_image(img_path)
        
        # è·å–æ³¨é‡Š
        target = []
        for ann in self.coco_data['annotations']:
            if ann['image_id'] == img_id:
                target.append(ann)
        
        target = {'image_id': img_id, 'annotations': target}
        
        if self._transforms is not None:
            img, target = self._transforms(img, target)
        
        return img, target
    
    def __len__(self):
        return len(self.ids)


# å…¼å®¹æ€§æ¥å£
def get_pid_dataset(image_set, args):
    """è·å–PIDæ•°æ®é›†çš„å…¼å®¹æ€§å‡½æ•°"""
    return build_pid_dataset(image_set, args)
