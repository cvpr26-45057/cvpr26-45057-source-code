#!/usr/bin/env python3
"""
ç®€åŒ–çš„PID2GraphæŸå¤±å‡½æ•°
ç›´æ¥å¤„ç†decoderè¾“å‡ºçš„ç´¢å¼•é¢„æµ‹ï¼Œæ— éœ€å¤æ‚åŒ¹é…å™¨
"""

import torch
import torch.nn.functional as F
from torch import nn

from util import box_ops
from util.misc import accuracy


class SimplePID2GraphCriterion(nn.Module):
    """
    ç®€åŒ–çš„PID2GraphæŸå¤±å‡½æ•°
    
    ç›´æ¥å¤„ç†decoderçš„è¾“å‡ºï¼š
    - pred_logits: [B, num_entities, num_classes+1]
    - pred_boxes: [B, num_entities, 4] 
    - rel_logits: [B, num_triplets, num_rel_classes+1]
    - subject_indices: [B, num_triplets, num_entities] ä¸»ä½“ç´¢å¼•é¢„æµ‹
    - object_indices: [B, num_triplets, num_entities] å®¢ä½“ç´¢å¼•é¢„æµ‹
    
    ç›®æ ‡æ ¼å¼ï¼ˆPID2Graphï¼‰ï¼š
    - boxes: [N, 4] å®ä½“è¾¹ç•Œæ¡†
    - labels: [N] å®ä½“æ ‡ç­¾
    - rel_annotations: [M, 3] [ä¸»ä½“ç´¢å¼•, å®¢ä½“ç´¢å¼•, å…³ç³»æ ‡ç­¾]
    """
    
    def __init__(self, num_classes, num_rel_classes, weight_dict, 
                 eos_coef=0.1, losses=['labels', 'boxes', 'relations']):
        """
        Args:
            num_classes: å®ä½“ç±»åˆ«æ•°ï¼ˆä¸åŒ…æ‹¬èƒŒæ™¯ï¼‰
            num_rel_classes: å…³ç³»ç±»åˆ«æ•°ï¼ˆä¸åŒ…æ‹¬æ— å…³ç³»ï¼‰
            weight_dict: æŸå¤±æƒé‡å­—å…¸
            eos_coef: èƒŒæ™¯ç±»æƒé‡
            losses: è¦è®¡ç®—çš„æŸå¤±ç±»å‹åˆ—è¡¨
        """
        super().__init__()
        self.num_classes = num_classes
        self.num_rel_classes = num_rel_classes
        self.weight_dict = weight_dict
        self.eos_coef = eos_coef
        self.losses = losses
        
        # ä¸ºå®ä½“åˆ†ç±»åˆ›å»ºæƒé‡ï¼ˆé™ä½èƒŒæ™¯ç±»æƒé‡ï¼‰
        empty_weight = torch.ones(self.num_classes + 1)
        empty_weight[-1] = self.eos_coef
        self.register_buffer('empty_weight', empty_weight)
        
        # ä¸ºå…³ç³»åˆ†ç±»åˆ›å»ºæƒé‡
        empty_weight_rel = torch.ones(self.num_rel_classes + 1)
        empty_weight_rel[-1] = self.eos_coef
        self.register_buffer('empty_weight_rel', empty_weight_rel)
        
        print(f"ğŸ”§ åˆå§‹åŒ–ç®€åŒ–PID2GraphæŸå¤±å‡½æ•°:")
        print(f"   å®ä½“ç±»åˆ«æ•°: {num_classes}")
        print(f"   å…³ç³»ç±»åˆ«æ•°: {num_rel_classes}")
        print(f"   æŸå¤±ç±»å‹: {losses}")

    def loss_labels(self, outputs, targets, num_boxes, log=True):
        """
        è®¡ç®—å®ä½“åˆ†ç±»æŸå¤±
        ä½¿ç”¨ç®€å•çš„å‰Kä¸ªé¢„æµ‹ä¸å‰Kä¸ªç›®æ ‡åŒ¹é…
        """
        assert 'pred_logits' in outputs
        src_logits = outputs['pred_logits']  # [B, num_entities, num_classes+1]
        
        # æ”¶é›†æ‰€æœ‰ç›®æ ‡
        all_target_labels = []
        all_target_valid = []
        
        for batch_idx, target in enumerate(targets):
            target_labels = target["labels"]  # [N]
            num_targets = len(target_labels)
            
            # åˆ›å»ºå¡«å……ç›®æ ‡ï¼ˆç”¨èƒŒæ™¯ç±»å¡«å……åˆ°num_entitiesé•¿åº¦ï¼‰
            padded_labels = torch.full((src_logits.shape[1],), self.num_classes, 
                                     dtype=torch.int64, device=src_logits.device)
            padded_labels[:num_targets] = target_labels
            
            # åˆ›å»ºæœ‰æ•ˆæ€§æ©ç 
            valid_mask = torch.zeros(src_logits.shape[1], dtype=torch.bool, device=src_logits.device)
            valid_mask[:num_targets] = True
            
            all_target_labels.append(padded_labels)
            all_target_valid.append(valid_mask)
        
        target_classes = torch.stack(all_target_labels)  # [B, num_entities]
        valid_masks = torch.stack(all_target_valid)      # [B, num_entities]
        
        # è®¡ç®—åˆ†ç±»æŸå¤±ï¼ˆåªå¯¹æœ‰æ•ˆä½ç½®ï¼‰
        # ç¡®ä¿æƒé‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        weight = self.empty_weight.to(src_logits.device)
        loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, 
                                 weight, reduction='none')  # [B, num_entities]
        
        # åªå¯¹æœ‰æ•ˆä½ç½®è®¡ç®—æŸå¤±
        loss_ce = loss_ce * valid_masks.float()
        loss_ce = loss_ce.sum() / valid_masks.sum().clamp(min=1)
        
        losses = {'loss_ce': loss_ce}

        if log:
            # è®¡ç®—å‡†ç¡®ç‡ï¼ˆåªå¯¹æœ‰æ•ˆä½ç½®ï¼‰
            pred_classes = src_logits.argmax(-1)  # [B, num_entities]
            correct = (pred_classes == target_classes) * valid_masks
            accuracy_val = correct.sum().float() / valid_masks.sum().clamp(min=1)
            losses['class_error'] = 100 - accuracy_val * 100
            
        return losses

    def loss_boxes(self, outputs, targets, num_boxes):
        """è®¡ç®—è¾¹ç•Œæ¡†å›å½’æŸå¤±"""
        assert 'pred_boxes' in outputs
        src_boxes = outputs['pred_boxes']  # [B, num_entities, 4]
        
        # æ”¶é›†æ‰€æœ‰ç›®æ ‡è¾¹ç•Œæ¡†
        all_target_boxes = []
        all_target_valid = []
        
        for batch_idx, target in enumerate(targets):
            target_boxes = target['boxes']  # [N, 4]
            num_targets = len(target_boxes)
            
            # åˆ›å»ºå¡«å……ç›®æ ‡ï¼ˆç”¨é›¶å¡«å……åˆ°num_entitiesé•¿åº¦ï¼‰
            padded_boxes = torch.zeros((src_boxes.shape[1], 4), device=src_boxes.device)
            padded_boxes[:num_targets] = target_boxes
            
            # åˆ›å»ºæœ‰æ•ˆæ€§æ©ç 
            valid_mask = torch.zeros(src_boxes.shape[1], dtype=torch.bool, device=src_boxes.device)
            valid_mask[:num_targets] = True
            
            all_target_boxes.append(padded_boxes)
            all_target_valid.append(valid_mask)
        
        target_boxes = torch.stack(all_target_boxes)  # [B, num_entities, 4]
        valid_masks = torch.stack(all_target_valid)   # [B, num_entities]
        
        # åªå¯¹æœ‰æ•ˆä½ç½®è®¡ç®—L1æŸå¤±
        loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction='none')  # [B, num_entities, 4]
        loss_bbox = loss_bbox.sum(-1) * valid_masks.float()  # [B, num_entities]
        loss_bbox = loss_bbox.sum() / valid_masks.sum().clamp(min=1)
        
        # è®¡ç®—GIoUæŸå¤±
        valid_src_boxes = src_boxes[valid_masks]      # [num_valid, 4]
        valid_target_boxes = target_boxes[valid_masks] # [num_valid, 4]
        
        if len(valid_src_boxes) > 0:
            loss_giou = 1 - torch.diag(box_ops.generalized_box_iou(
                box_ops.box_cxcywh_to_xyxy(valid_src_boxes),
                box_ops.box_cxcywh_to_xyxy(valid_target_boxes)))
            loss_giou = loss_giou.mean()
        else:
            loss_giou = torch.tensor(0.0, device=src_boxes.device)
            
        losses = {
            'loss_bbox': loss_bbox,
            'loss_giou': loss_giou
        }
        return losses

    def loss_relations(self, outputs, targets, num_boxes, log=True):
        """
        è®¡ç®—å…³ç³»æŸå¤±
        åŒ…æ‹¬å…³ç³»åˆ†ç±»ã€ä¸»ä½“ç´¢å¼•é¢„æµ‹ã€å®¢ä½“ç´¢å¼•é¢„æµ‹
        """
        assert 'rel_logits' in outputs
        assert 'subject_indices' in outputs  
        assert 'object_indices' in outputs
        
        rel_logits = outputs['rel_logits']        # [B, num_triplets, num_rel_classes+1]
        subject_indices = outputs['subject_indices']  # [B, num_triplets, num_entities]
        object_indices = outputs['object_indices']    # [B, num_triplets, num_entities]
        
        # æ”¶é›†æ‰€æœ‰ç›®æ ‡å…³ç³»
        all_target_rels = []
        all_target_subjects = []
        all_target_objects = []
        all_rel_valid = []
        
        for batch_idx, target in enumerate(targets):
            rel_annotations = target["rel_annotations"]  # [M, 3] = [sub_idx, obj_idx, rel_label]
            num_rels = len(rel_annotations)
            
            # åˆ›å»ºå¡«å……ç›®æ ‡
            padded_rels = torch.full((rel_logits.shape[1],), self.num_rel_classes, 
                                   dtype=torch.int64, device=rel_logits.device)
            padded_subjects = torch.zeros(rel_logits.shape[1], dtype=torch.int64, device=rel_logits.device)
            padded_objects = torch.zeros(rel_logits.shape[1], dtype=torch.int64, device=rel_logits.device)
            
            if num_rels > 0:
                padded_rels[:num_rels] = rel_annotations[:, 2]      # å…³ç³»æ ‡ç­¾
                padded_subjects[:num_rels] = rel_annotations[:, 0]  # ä¸»ä½“ç´¢å¼•
                padded_objects[:num_rels] = rel_annotations[:, 1]   # å®¢ä½“ç´¢å¼•
            
            # åˆ›å»ºæœ‰æ•ˆæ€§æ©ç 
            valid_mask = torch.zeros(rel_logits.shape[1], dtype=torch.bool, device=rel_logits.device)
            valid_mask[:num_rels] = True
            
            all_target_rels.append(padded_rels)
            all_target_subjects.append(padded_subjects)
            all_target_objects.append(padded_objects)
            all_rel_valid.append(valid_mask)
        
        target_rels = torch.stack(all_target_rels)      # [B, num_triplets]
        target_subjects = torch.stack(all_target_subjects)  # [B, num_triplets]
        target_objects = torch.stack(all_target_objects)    # [B, num_triplets]
        rel_valid_masks = torch.stack(all_rel_valid)        # [B, num_triplets]
        
        # å…³ç³»åˆ†ç±»æŸå¤±
        weight_rel = self.empty_weight_rel.to(rel_logits.device)
        loss_rel_ce = F.cross_entropy(rel_logits.transpose(1, 2), target_rels, 
                                     weight_rel, reduction='none')
        loss_rel_ce = loss_rel_ce * rel_valid_masks.float()
        loss_rel_ce = loss_rel_ce.sum() / rel_valid_masks.sum().clamp(min=1)
        
        # ä¸»ä½“ç´¢å¼•é¢„æµ‹æŸå¤±
        loss_subject = F.cross_entropy(subject_indices.transpose(1, 2), target_subjects, reduction='none')
        loss_subject = loss_subject * rel_valid_masks.float()
        loss_subject = loss_subject.sum() / rel_valid_masks.sum().clamp(min=1)
        
        # å®¢ä½“ç´¢å¼•é¢„æµ‹æŸå¤±
        loss_object = F.cross_entropy(object_indices.transpose(1, 2), target_objects, reduction='none')
        loss_object = loss_object * rel_valid_masks.float()
        loss_object = loss_object.sum() / rel_valid_masks.sum().clamp(min=1)
        
        losses = {
            'loss_rel': loss_rel_ce,
            'loss_subject': loss_subject,
            'loss_object': loss_object
        }

        if log:
            # è®¡ç®—å‡†ç¡®ç‡
            pred_rels = rel_logits.argmax(-1)
            pred_subjects = subject_indices.argmax(-1)  
            pred_objects = object_indices.argmax(-1)
            
            rel_correct = (pred_rels == target_rels) * rel_valid_masks
            subj_correct = (pred_subjects == target_subjects) * rel_valid_masks
            obj_correct = (pred_objects == target_objects) * rel_valid_masks
            
            valid_count = rel_valid_masks.sum().clamp(min=1)
            losses['rel_error'] = 100 - (rel_correct.sum().float() / valid_count) * 100
            losses['subject_error'] = 100 - (subj_correct.sum().float() / valid_count) * 100
            losses['object_error'] = 100 - (obj_correct.sum().float() / valid_count) * 100
            
        return losses

    def get_loss(self, loss, outputs, targets, num_boxes, **kwargs):
        """è·å–æŒ‡å®šç±»å‹çš„æŸå¤±"""
        loss_map = {
            'labels': self.loss_labels,
            'boxes': self.loss_boxes,
            'relations': self.loss_relations,
        }
        assert loss in loss_map, f'do you really want to compute {loss} loss?'
        return loss_map[loss](outputs, targets, num_boxes, **kwargs)

    def forward(self, outputs, targets):
        """
        å‰å‘ä¼ æ’­è®¡ç®—æŸå¤±
        
        Args:
            outputs: æ¨¡å‹è¾“å‡ºå­—å…¸
            targets: ç›®æ ‡åˆ—è¡¨
                
        Returns:
            æŸå¤±å­—å…¸
        """
        outputs_without_aux = {k: v for k, v in outputs.items() if k != 'aux_outputs'}

        # è®¡ç®—æ‰€æœ‰ç›®æ ‡çš„æ•°é‡ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
        num_boxes = sum(len(t["labels"]) + len(t["rel_annotations"]) for t in targets)
        num_boxes = max(num_boxes, 1)  # é¿å…é™¤é›¶

        # è®¡ç®—æ‰€æœ‰æŸå¤±
        losses = {}
        for loss in self.losses:
            losses.update(self.get_loss(loss, outputs_without_aux, targets, num_boxes))

        # å¤„ç†è¾…åŠ©æŸå¤±ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'aux_outputs' in outputs:
            for i, aux_outputs in enumerate(outputs['aux_outputs']):
                for loss in self.losses:
                    kwargs = {}
                    if loss == 'labels':
                        kwargs = {'log': False}
                    elif loss == 'relations':
                        kwargs = {'log': False}
                    l_dict = self.get_loss(loss, aux_outputs, targets, num_boxes, **kwargs)
                    l_dict = {k + f'_{i}': v for k, v in l_dict.items()}
                    losses.update(l_dict)

        return losses


def build_simple_pid2graph_criterion(args):
    """æ„å»ºç®€åŒ–çš„PID2Graphæ ¼å¼æŸå¤±å‡½æ•°"""
    
    # æŸå¤±æƒé‡
    weight_dict = {
        'loss_ce': getattr(args, 'cls_loss_coef', 1),
        'loss_bbox': getattr(args, 'bbox_loss_coef', 5),
        'loss_giou': getattr(args, 'giou_loss_coef', 2),
        'loss_rel': getattr(args, 'rel_loss_coef', 1),
        'loss_subject': getattr(args, 'subject_loss_coef', 1),
        'loss_object': getattr(args, 'object_loss_coef', 1),
    }
    
    # è¾…åŠ©æŸå¤±æƒé‡
    if getattr(args, 'aux_loss', False):
        aux_weight_dict = {}
        for i in range(getattr(args, 'dec_layers', 6) - 1):
            aux_weight_dict.update({k + f'_{i}': v for k, v in weight_dict.items()})
        weight_dict.update(aux_weight_dict)
    
    losses = ['labels', 'boxes', 'relations']
    
    criterion = SimplePID2GraphCriterion(
        num_classes=getattr(args, 'num_classes', 91),
        num_rel_classes=getattr(args, 'num_rel_classes', 50),
        weight_dict=weight_dict,
        eos_coef=getattr(args, 'eos_coef', 0.1),
        losses=losses
    )
    
    print("âœ… ç®€åŒ–PID2GraphæŸå¤±å‡½æ•°æ„å»ºå®Œæˆ")
    return criterion, weight_dict
